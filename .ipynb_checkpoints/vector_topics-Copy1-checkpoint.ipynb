{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load speech file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from pickle file\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"speeches.pickle\", \"rb\")\n",
    "speech_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>speaker</th>\n",
       "      <th>date</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convention</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016</td>\n",
       "      <td>Thank you all for the great convention that we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convention</td>\n",
       "      <td>Robert Dole</td>\n",
       "      <td>1996</td>\n",
       "      <td>The folks in Hollywood would be happy to know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>convention</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>2000</td>\n",
       "      <td>Thank you. Thank you for this honor. [,],Thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>convention</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>2004</td>\n",
       "      <td>When I said those words 4 years ago, none of u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>convention</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>2008</td>\n",
       "      <td>Tonight, I have a privilege given few American...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type          speaker  date  \\\n",
       "0  convention  Hillary Clinton  2016   \n",
       "1  convention      Robert Dole  1996   \n",
       "2  convention   George W. Bush  2000   \n",
       "3  convention   George W. Bush  2004   \n",
       "4  convention      John McCain  2008   \n",
       "\n",
       "                                              speech  \n",
       "0  Thank you all for the great convention that we...  \n",
       "1  The folks in Hollywood would be happy to know ...  \n",
       "2  Thank you. Thank you for this honor. [,],Thank...  \n",
       "3  When I said those words 4 years ago, none of u...  \n",
       "4  Tonight, I have a privilege given few American...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_text = speech_df['speech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citizens united states 183\n",
      "      ending june 30 177\n",
      "government united states 175\n",
      "    year ending june 168\n",
      "people united states 161\n",
      "    last fiscal year 145\n",
      "  fiscal year ending 144\n",
      "last session congress 141\n",
      " last annual message 138\n",
      "president united states 132\n",
      "united states america 116\n",
      " united states great 104\n",
      "  part united states 100\n",
      "states great britain 89\n",
      "congress last session 82\n",
      "    next fiscal year 76\n",
      "report secretary war 76\n",
      " present fiscal year 75\n",
      "report secretary treasury 69\n",
      "    year ending 30th 68\n",
      " current fiscal year 67\n",
      "united states government 66\n",
      "report secretary navy 66\n",
      "       ended june 30 65\n",
      "     year ended june 64\n",
      "constitution united states 62\n",
      "    fiscal year 1947 62\n",
      "interstate commerce commission 60\n",
      "        world war ii 59\n",
      "  bank united states 59\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop += ['.', ',', '(', ')', \"'\", '\"']\n",
    "stop = set(stop)\n",
    "\n",
    "n = 3\n",
    "for doc in speech_text:\n",
    "    words = TextBlob(doc.lower()).words  # tokenize words\n",
    "    words = [w for w in words if w not in stop]   \n",
    "    bigrams = ngrams(words, n)\n",
    "    counter += Counter(bigrams)\n",
    "\n",
    "for phrase, count in counter.most_common(30):\n",
    "    print('%20s %i' % (\" \".join(phrase), count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VC and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),\n",
    "    token_pattern=\"\\\\b[a-z][a-z]+\\\\b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='\\\\b[a-z][a-z]+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(speech_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = count_vectorizer.transform(speech_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 5\n",
      "iteration: 2 of max_iter: 5\n",
      "iteration: 3 of max_iter: 5\n",
      "iteration: 4 of max_iter: 5\n",
      "iteration: 5 of max_iter: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=15, n_jobs=-1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics = 15\n",
    "\n",
    "lda = decomposition.LatentDirichletAllocation(\n",
    "    n_components=n_topics, \n",
    "    learning_method=\"online\", \n",
    "    verbose=1, \n",
    "    max_iter=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lda.fit(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: people government great country america states american world new years nation time united national united states\n",
      "Topic #1: america world people time american government country years nation new party united states make president\n",
      "Topic #2: people government new great country american states world america shall party time men years power\n",
      "Topic #3: america people american nation president new government country party world states audience members years opponent great\n",
      "Topic #4: people america government nation great time world president years party country states know peace united\n",
      "Topic #5: government states united congress people united states year country great public new time american war world\n",
      "Topic #6: america government people world new great american states president nation united country years peace president obama\n",
      "Topic #7: america people government new country years world nation american time states let make enriched ennobled president\n",
      "Topic #8: america people world new government nation let american time great years work states country americans\n",
      "Topic #9: people country government america american great world president states time new public make years united\n",
      "Topic #10: people government world country america new american nation make years shall time believe president states\n",
      "Topic #11: people government great america new world american nation president time years work country peace party\n",
      "Topic #12: people government america country world new nation great years shall party states time united american\n",
      "Topic #13: people government world america country states party american years great power united nation new time\n",
      "Topic #14: people world government peace free great american republican states country shall make power men war\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, count_vectorizer.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF and NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='\\\\b[a-z][a-z]+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),\n",
    "    token_pattern=\"\\\\b[a-z][a-z]+\\\\b\"\n",
    ")\n",
    "\n",
    "t_vectorizer.fit(speech_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_counts = t_vectorizer.transform(speech_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=5,\n",
       "  n_components=15, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics = 15\n",
    "\n",
    "nmf = decomposition.NMF(\n",
    "    n_components=n_topics,\n",
    "    max_iter=5\n",
    ")\n",
    "\n",
    "nmf.fit(t_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: states government united states united congress year public general subject country\n",
      "Topic #1: america tonight americans ve people new jobs american work children\n",
      "Topic #2: government economic federal program world congress people national year new\n",
      "Topic #3: people world nation government shall peace great freedom nations men\n",
      "Topic #4: soviet world oil programs energy year billion soviet union percent nuclear\n",
      "Topic #5: applause america ve iraq let tonight people applause let congress iraqi\n",
      "Topic #6: world america tonight americans president let peace united war free\n",
      "Topic #7: people government constitution president union federal energy congress strategic states\n",
      "Topic #8: congress vietnam tonight think years year commitments believe surtax kappel\n",
      "Topic #9: interstate law business men corporations conditions work interstate commerce man industrial\n",
      "Topic #10: party ve republican democratic platform democratic party people president republican party audience\n",
      "Topic #11: war fighting japanese forces production enemy world united nations military united\n",
      "Topic #12: year public present country treasury indian silver necessary militia vessels\n",
      "Topic #13: mexico texas mexican war public government banks treasury states country\n",
      "Topic #14: iraq terrorists america saddam terror iraqi saddam hussein hussein weapons freedom\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf, t_vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='\\\\b[a-z][a-z]+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "t_vectorizer.fit(speech_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_counts = t_vectorizer.transform(speech_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=5,\n",
       "  n_components=30, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics = 30\n",
    "\n",
    "nmf = decomposition.NMF(\n",
    "    n_components=n_topics,\n",
    "    max_iter=5\n",
    ")\n",
    "\n",
    "nmf.fit(t_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: congress year department general secretary report subject service attention law\n",
      "Topic #1: america tonight americans let jobs world years help children work\n",
      "Topic #2: economic program world federal congress programs year farm development security\n",
      "Topic #3: world freedom free let men peoples shall man america unity\n",
      "Topic #4: spain public commerce powers vessels effect colonies congress treaty duties\n",
      "Topic #5: business interstate law corporations public conditions work industrial men tariff\n",
      "Topic #6: applause ve america let budget tonight congress iraq year laughter\n",
      "Topic #7: constitution union shall public citizens powers state laws interests rights\n",
      "Topic #8: party republican platform democratic president nomination say campaign convention leadership\n",
      "Topic #9: ve ll don jobs soviet oil know going want didn\n",
      "Topic #10: banks gold notes silver public currency year cent treasury financial\n",
      "Topic #11: mexico texas treaty congress mexican territory minister treasury act state\n",
      "Topic #12: year billion help percent budget congress million tax health program\n",
      "Topic #13: iraq terrorists america terror iraqi saddam terrorist afghanistan hussein freedom\n",
      "Topic #14: public bank general subject treasury present banks objects notes paper\n",
      "Topic #15: shall oath upbraidings knowingly incurring america willingly ceremony reposed injunctions\n",
      "Topic #16: gentlemen shall congress treaty commissioners measures commerce necessary representatives philadelphia\n",
      "Topic #17: energy programs president strategic oil percent federal congress union years\n",
      "Topic #18: democracy life men know problems spirit democratic years speaks faith\n",
      "Topic #19: vietnam tonight congress years think commitments year believe surtax president\n",
      "Topic #20: enemy british savages prisoners honorable savage rights command massacre service\n",
      "Topic #21: tariff trade men thought shall duty present treasury matter ships\n",
      "Topic #22: shall vessels harbors necessary principal debt orleans citizens friendship port\n",
      "Topic #23: british orders decrees edicts congress minister council militia neutral ports\n",
      "Topic #24: today journey generation let creed oath founding words learned god\n",
      "Topic #25: president audience clinton opponent reagan foreign france wages protective trade\n",
      "Topic #26: republic world america civilization relationship railway understanding citizenship party conscience\n",
      "Topic #27: indians provision proper information tribes measures militia laws laid satisfaction\n",
      "Topic #28: century children challenge bridge parents thank welfare work college years\n",
      "Topic #29: convention nomination inst notifying dennison supplanting complimentary thanking obedient hon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf, t_vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
